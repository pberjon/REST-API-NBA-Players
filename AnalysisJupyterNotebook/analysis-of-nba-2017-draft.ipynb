{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IMPORTATIONS","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"**Librairies**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, accuracy_score, roc_auc_score\nplt.style.use('ggplot')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loading the data into a dataframe**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/nba-general-data/nbalogreg-logistic-regression-exercise-1-QueryResult.csv\", delimiter=',')\n#df.target_5yrs = df.target_5yrs.map({0.0:\"career length < 5 years\", 1.0:\"career length >= 5 years\"})\ndf.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = df.corr()\ncorr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(ncols=1,figsize=(17,6))\n\nsns.countplot(x='target_5yrs',ax=axes,data=df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see here that we have a slightly unbalanced dataset, as we have a little more players with a career of more than 5 years.","metadata":{}},{"cell_type":"code","source":"sns.heatmap(corr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we see that the correlation coefficients between target_5yrs and the other variables don't tell us much, given that they are all quite close. In summary, they are positive, so we can conclude that their increase will promote the length of a player's career, but there are no variables that really stand out from the others. The variable with the highest correlation rate with target_5yrs happens to be gp, the number of matches played.\n\nWith this in mind, we will determine the variables to favor by studying the stripplots of the different variables with target_5yrs.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(5, 3, figsize=(18, 10))\n\nfig.suptitle('Répartition des variables en fonction de leur durée de carrière')\n\nsns.stripplot(ax=axes[0, 0], data=df, x='target_5yrs', y='pts')\nsns.stripplot(ax=axes[0, 1], data=df, x='target_5yrs', y='min')\nsns.stripplot(ax=axes[0, 2], data=df, x='target_5yrs', y='reb')\nsns.stripplot(ax=axes[1, 0], data=df, x='target_5yrs', y='ast')\nsns.stripplot(ax=axes[1, 1], data=df, x='target_5yrs', y='blk')\nsns.stripplot(ax=axes[1, 2], data=df, x='target_5yrs', y='tov')\nsns.stripplot(ax=axes[2, 0], data=df, x='target_5yrs', y='gp')\nsns.stripplot(ax=axes[2, 1], data=df, x='target_5yrs', y='fgm')\nsns.stripplot(ax=axes[2, 2], data=df, x='target_5yrs', y='fg')\nsns.stripplot(ax=axes[3, 0], data=df, x='target_5yrs', y='3p_made')\nsns.stripplot(ax=axes[3, 1], data=df, x='target_5yrs', y='3pa')\nsns.stripplot(ax=axes[3, 2], data=df, x='target_5yrs', y='3p')\nsns.stripplot(ax=axes[3, 0], data=df, x='target_5yrs', y='ftm')\nsns.stripplot(ax=axes[3, 1], data=df, x='target_5yrs', y='fta')\nsns.stripplot(ax=axes[3, 2], data=df, x='target_5yrs', y='ft')\nsns.stripplot(ax=axes[4, 0], data=df, x='target_5yrs', y='oreb')\nsns.stripplot(ax=axes[4, 1], data=df, x='target_5yrs', y='dreb')\nsns.stripplot(ax=axes[4, 2], data=df, x='target_5yrs', y='stl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can clearly see that ten variables are really relevant to distinguish a player who will have a career lasting more than 5 years: pts, reb, ast, tov, fgm, ftm, fta, oreb, dreb, stl, blk.","metadata":{}},{"cell_type":"markdown","source":"We will choose here to consider certain data by processing them \"per match played\", like the variable pts.","metadata":{}},{"cell_type":"code","source":"def by_game(df, variable):\n    df[str(variable) + \"_by_game\"] = df[variable]/df.gp\n\nfor var in [\"pts\",\"min\",\"tov\",\"blk\",\"ast\",\"stl\",\"reb\",\"fgm\",\"ftm\",\"fta\",\"oreb\",\"dreb\"]:\n    by_game(df, var)\n    df = df.drop(var,axis=1)\n\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we remove the non-useful variables:","metadata":{}},{"cell_type":"code","source":"for column in df.columns:\n    if \"_by_game\" not in column and \"target_5yrs\" not in column:\n        df = df.drop(column,axis=1)\n\ndf.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shuffled_rows = np.random.permutation(players.index)\ndf = df.iloc[shuffled_rows]\ndf.head()\ndf.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr()[\"pts_by_game\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df, hue=\"target_5yrs\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Implementation of models and tests","metadata":{}},{"cell_type":"markdown","source":"Here we will use the given test function with the subject. However, we have modified it somewhat: it has been separated into two functions; one performing the prediction on the test set, and the other on the practice set. The second will be used to determine if a model is overfitting.","metadata":{}},{"cell_type":"code","source":"df.drop(['target_5yrs'],axis=1).columns.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import recall_score\nfrom sklearn.svm import SVC\n\ndef score_classifier_test(dataset,classifier,labels):\n\n    \"\"\"\n    performs 3 random trainings/tests to build a confusion matrix and prints results with precision and recall scores\n    :param dataset: the dataset to work on\n    :param classifier: the classifier to use\n    :param labels: the labels used for training and validation\n    :return:\n    \"\"\"\n\n    kf = KFold(n_splits=3,random_state=50,shuffle=True)\n    confusion_mat = np.zeros((2,2))\n    recall = 0\n    for training_ids,test_ids in kf.split(dataset):\n        training_set = dataset[training_ids]\n        training_labels = labels[training_ids]\n        test_set = dataset[test_ids]\n        test_labels = labels[test_ids]\n        classifier.fit(training_set,training_labels)\n        predicted_labels = classifier.predict(test_set)\n        confusion_mat+=confusion_matrix(test_labels,predicted_labels)\n        recall += recall_score(test_labels, predicted_labels)\n    recall/=3\n    return(confusion_mat, recall)\n\ndef score_classifier_train(dataset,classifier,labels):\n\n    \"\"\"\n    performs 3 random trainings/tests to build a confusion matrix and prints results with precision and recall scores\n    :param dataset: the dataset to work on\n    :param classifier: the classifier to use\n    :param labels: the labels used for training and validation\n    :return:\n    \"\"\"\n\n    kf = KFold(n_splits=3,random_state=50,shuffle=True)\n    confusion_mat = np.zeros((2,2))\n    recall = 0\n    for training_ids,test_ids in kf.split(dataset):\n        training_set = dataset[training_ids]\n        training_labels = labels[training_ids]\n        test_set = dataset[test_ids]\n        test_labels = labels[test_ids]\n        classifier.fit(training_set,training_labels)\n        predicted_labels = classifier.predict(training_set)\n        confusion_mat+=confusion_matrix(training_labels,predicted_labels)\n        recall += recall_score(training_labels, predicted_labels)\n    recall/=3\n    return(confusion_mat, recall)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Set up of models and test function**","metadata":{}},{"cell_type":"markdown","source":"Similarly, we have modified this part as well by removing the drops from the 'name' variable since we had already done so before.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\n\nlr = LogisticRegression()\nmlp = MLPClassifier()\nrf = RandomForestClassifier()\nsvc = SVC()\n\ndef test_model(model, type):\n    # extract names, labels, features names and values\n    labels = df['target_5yrs'].values # labels\n    paramset = df.drop(['target_5yrs'],axis=1).columns.values\n    df_vals = df.drop(['target_5yrs'],axis=1).values\n\n    # replacing Nan values (only present when no 3 points attempts have been performed by a player)\n    for x in np.argwhere(np.isnan(df_vals)):\n        df_vals[x]=0.0\n\n    # normalize dataset\n    X = MinMaxScaler().fit_transform(df_vals)\n\n    #example of scoring with support vector classifier\n    if (type == 'test'): # test predictions\n        return score_classifier_test(X,model,labels)\n    else: # train predictions to conclude on the overfitting\n        return score_classifier_train(X,model,labels)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model test**","metadata":{}},{"cell_type":"code","source":"accuracy_lr = test_model(lr,'test')[1]\naccuracy_mlp = test_model(mlp,'test')[1]\naccuracy_rf = test_model(rf,'test')[1]\naccuracy_svc = test_model(svc,'test')[1]\n\nprint('Test Accuracy of Logistic Regression: %.3f' % accuracy_lr)\nprint('Test Accuracy of MLP: %.3f' % accuracy_mlp)\nprint('Test Accuracy of Random Forest: %.3f' % accuracy_rf)\nprint('Test Accuracy of SVC: %.3f' % accuracy_svc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Overfitting tests**","metadata":{}},{"cell_type":"code","source":"accuracy_lr = test_model(lr,'train')[1]\naccuracy_mlp = test_model(mlp,'train')[1]\naccuracy_rf = test_model(rf,'train')[1]\naccuracy_svc = test_model(svc,'train')[1]\n\nprint('Train Accuracy of Logistic Regression: %.3f' % accuracy_lr)\nprint('Train Accuracy of MLP: %.3f' % accuracy_mlp)\nprint('Train Accuracy of Random Forest: %.3f' % accuracy_rf)\nprint('Train Accuracy of SVC: %.3f' % accuracy_svc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The only model that seems to overfit is the Random Forest. It seems obvious here that the model to choose is therefore the logistic regression model.","metadata":{}},{"cell_type":"markdown","source":"**Save the model**","metadata":{}},{"cell_type":"code","source":"import pickle\n\n\nPkl_Filename = \"lr.pkl\"  \n\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(lr, file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}